{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook should be ran at colab. Huggingface does not like local computing power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdgC1O7yk-w3"
   },
   "source": [
    "# Installing required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11925,
     "status": "ok",
     "timestamp": 1625052415044,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "MOl1XqiTk5SS",
    "outputId": "494e2084-f002-488b-bd0d-0e89eead3f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.12)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.5.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
      "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
      "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install tensorflow-addons\n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PM9MW30FlEek"
   },
   "source": [
    "# Load Required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2892,
     "status": "ok",
     "timestamp": 1625052417930,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "p6u5uql_lGO9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from keras import metrics\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from skopt import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1625052417933,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "tYyCYdJYlINU",
    "outputId": "17c46df7-e8ab-4bec-f266-45abb107a1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mount drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vtwbvj72lKCE"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace value of BASE_PATH by the directory in which the data is located.\n",
    "BASE_PATH='/content/drive/MyDrive/Thesis/RobBert/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1625052417934,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "kdpUazjxlMI_"
   },
   "outputs": [],
   "source": [
    "with open('texts.pkl', 'rb') as f:\n",
    "  text_list = pickle.load(f)\n",
    "with open('labels.pkl', 'rb') as f:\n",
    "  label_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtF_J8r6lWlF"
   },
   "source": [
    "# Model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1625052417934,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "2cnkkdpdofTy"
   },
   "outputs": [],
   "source": [
    "def to_optimize(input_lst):\n",
    "  '''\n",
    "  This function takes a list of hyperparameters, and outputs the negative macro-averaged F1 score.\n",
    "  '''\n",
    "  # Params:\n",
    "  # Optimizer function\n",
    "  opt_function = input_lst[0]\n",
    "  # Add in learning rate\n",
    "  opt_function = opt_function(learning_rate=input_lst[1])\n",
    "  take_weights = True\n",
    "  batchsize = input_lst[2]\n",
    "  num_epochs = input_lst[3]\n",
    "  print('clear sessions')\n",
    "  # We train several models in succession, so we need to reset the tensorflow graph\n",
    "  K.clear_session()\n",
    "  tf.compat.v1.reset_default_graph\n",
    "  tf.compat.v1.Session()\n",
    "  # Inititalize model & tokenizer\n",
    "  print('begin downloaden tokenizer')\n",
    "  tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "  print('begin downloaden model')\n",
    "  model = TFRobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\", num_labels = 9)\n",
    "  print('downloaden klaar')\n",
    "  # Encode labels into integers\n",
    "  le = LabelEncoder()\n",
    "  labels = le.fit_transform(label_list)\n",
    "\n",
    "  # Split into train, test, and validation set\n",
    "  train_texts, test_texts, train_labels, test_labels = train_test_split(text_list, labels, test_size=.2, random_state = 420)\n",
    "  train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size = 0.2, random_state = 420)\n",
    "\n",
    "  # Tokenize text \n",
    "  train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "  test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "  val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "  # Transform data into tensorflow-dataset objects\n",
    "  train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_labels\n",
    "  )).shuffle(len(train_texts))\n",
    "  test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "      dict(test_encodings),\n",
    "      test_labels\n",
    "  )).shuffle(len(test_texts))\n",
    "  val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "      dict(val_encodings),\n",
    "      val_labels\n",
    "  )).shuffle(len(val_texts))\n",
    "  # Define the model\n",
    "  model.compile(optimizer=opt_function, \n",
    "                loss=model.compute_loss, \n",
    "                metrics=['accuracy'] \n",
    "                ) \n",
    "  # Start Training\n",
    "  print('--------------------STARTING TRAINING--------------------')\n",
    "  print(f'Optimization function: {opt_function}')\n",
    "  print(f'Learning rate: {input_lst[1]}')\n",
    "  print(f'Batch size: {batchsize}')\n",
    "  if take_weights == False:\n",
    "    history = model.fit(train_dataset.batch(batchsize), \n",
    "                        epochs=num_epochs, \n",
    "                        batch_size=batchsize, \n",
    "                        validation_data=val_dataset.batch(batchsize)\n",
    "                        )\n",
    "  else:\n",
    "    class_weights = dict(enumerate(compute_class_weight('balanced', np.unique(labels), labels)))\n",
    "    history = model.fit(train_dataset.batch(batchsize), \n",
    "                        epochs=num_epochs, batch_size=batchsize, \n",
    "                        validation_data=val_dataset.batch(batchsize), \n",
    "                        class_weight=class_weights\n",
    "                        )\n",
    "  \n",
    "  model.save_pretrained(BASE_PATH+f\"bayesianopt_epochs{num_epochs}_BS{batchsize}_OPT{opt_function}_LR{input_lst[1]}\")\n",
    "  # Save history as well for plotting later on\n",
    "  with open(BASE_PATH+f\"HISTORY_bayesianopt_epochs{num_epochs}_BS{batchsize}_OPT{opt_function}_LR{input_lst[1]}\", 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "  # model.predict outputs logits, so we need to pass them through a softmax layer\n",
    "  predictions = tf.nn.softmax(model.predict(test_dataset.batch(batchsize)).logits)\n",
    "  # Take labels out of the tensorflow dataset object\n",
    "  test_labels = np.concatenate([y for x, y in test_dataset.batch(batchsize)], axis=0)\n",
    "  # Calculate the macro-averaged f1 score.\n",
    "  f1_macro = f1_score(test_labels, np.argmax(predictions, axis=1), average='macro')\n",
    "  print(f\"macro f1_score: {f1_macro}\")\n",
    "  # Delete model from memory\n",
    "  del model\n",
    "  return -f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1625052417934,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "6LD-2m7LrIwO"
   },
   "outputs": [],
   "source": [
    "# This cell defines the search space for the bayesian optimization\n",
    "d_optimizer = space.Categorical(categories=[tf.keras.optimizers.Adam, \n",
    "                                            tf.keras.optimizers.SGD,\n",
    "                                            tf.keras.optimizers.Adamax,\n",
    "                                            ], name='optimizer function')\n",
    "d_learning_rate = space.Real(low=1e-5, high=1e-1, name='learing rate')\n",
    "d_batchsize = space.Integer(low=4, high=6, name='batch size')\n",
    "d_epochs = space.Integer(low=1, high=10, name='number of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1625052417935,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "c0cZEQ-WtRMX"
   },
   "outputs": [],
   "source": [
    "# Define the dimensions, these will be put in the model function (to_optimize)\n",
    "dimensions = [d_optimizer, d_learning_rate, d_batchsize, d_epochs]\n",
    "# Define the starting set of HP's\n",
    "default = [tf.keras.optimizers.SGD, 1e-5, 4, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9937115,
     "status": "ok",
     "timestamp": 1625062355038,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "CcvBFLe8tZx3",
    "outputId": "7dc92d6b-1627-4375-87a0-5248f9bfeb57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f61c298d790>\n",
      "Learning rate: 1e-05\n",
      "Batch size: 4\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f62744c4f30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f62744c4f30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f629fd6fdd0> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function wrap at 0x7f629fd6fdd0> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.1539 - accuracy: 0.1401WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 100s 262ms/step - loss: 2.1539 - accuracy: 0.1401 - val_loss: 2.2189 - val_accuracy: 0.1257\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 47s 247ms/step - loss: 2.1393 - accuracy: 0.1584 - val_loss: 2.2168 - val_accuracy: 0.1204\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 2.1381 - accuracy: 0.1440 - val_loss: 2.2145 - val_accuracy: 0.1309\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 2.1453 - accuracy: 0.1387 - val_loss: 2.2125 - val_accuracy: 0.1257\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 2.1508 - accuracy: 0.1217 - val_loss: 2.2102 - val_accuracy: 0.1257\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 2.1323 - accuracy: 0.1492 - val_loss: 2.2077 - val_accuracy: 0.1257\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 2.1392 - accuracy: 0.1479 - val_loss: 2.2051 - val_accuracy: 0.1309\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 47s 247ms/step - loss: 2.1451 - accuracy: 0.1387 - val_loss: 2.2023 - val_accuracy: 0.1309\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 2.1346 - accuracy: 0.1518 - val_loss: 2.2001 - val_accuracy: 0.1361\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 2.1396 - accuracy: 0.1427 - val_loss: 2.1980 - val_accuracy: 0.1414\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.04341387259980059\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f61c28e4a10>\n",
      "Learning rate: 0.09325641036027252\n",
      "Batch size: 4\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 19.5061 - accuracy: 0.0995WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 68s 268ms/step - loss: 19.5061 - accuracy: 0.0995 - val_loss: 8.3593 - val_accuracy: 0.1466\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 48s 252ms/step - loss: 16.0879 - accuracy: 0.1139 - val_loss: 7.1816 - val_accuracy: 0.2513\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 17.9845 - accuracy: 0.0995 - val_loss: 32.9524 - val_accuracy: 0.0262\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 17.8145 - accuracy: 0.1086 - val_loss: 12.1198 - val_accuracy: 0.1466\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 17.0090 - accuracy: 0.1165 - val_loss: 6.0914 - val_accuracy: 0.1518\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 16.0551 - accuracy: 0.1309 - val_loss: 6.4230 - val_accuracy: 0.1466\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 48s 252ms/step - loss: 14.6261 - accuracy: 0.1139 - val_loss: 9.2043 - val_accuracy: 0.0576\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 48s 252ms/step - loss: 12.8518 - accuracy: 0.1113 - val_loss: 14.6894 - val_accuracy: 0.0262\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 16.6957 - accuracy: 0.0955 - val_loss: 10.2780 - val_accuracy: 0.1466\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 17.2393 - accuracy: 0.1126 - val_loss: 19.8477 - val_accuracy: 0.1466\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.039612676056338024\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6106174bd0>\n",
      "Learning rate: 0.03966410692232967\n",
      "Batch size: 5\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - ETA: 0s - loss: 31.7127 - accuracy: 0.1113WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - 67s 323ms/step - loss: 31.7127 - accuracy: 0.1113 - val_loss: 33.6993 - val_accuracy: 0.0105\n",
      "Epoch 2/7\n",
      "153/153 [==============================] - 46s 302ms/step - loss: 36.2618 - accuracy: 0.1034 - val_loss: 40.3122 - val_accuracy: 0.0576\n",
      "Epoch 3/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 29.6922 - accuracy: 0.1113 - val_loss: 31.0861 - val_accuracy: 0.2513\n",
      "Epoch 4/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 32.0954 - accuracy: 0.1322 - val_loss: 42.4398 - val_accuracy: 0.0262\n",
      "Epoch 5/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 29.8204 - accuracy: 0.1270 - val_loss: 38.3182 - val_accuracy: 0.0262\n",
      "Epoch 6/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 30.6362 - accuracy: 0.1414 - val_loss: 47.3987 - val_accuracy: 0.0785\n",
      "Epoch 7/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 31.1463 - accuracy: 0.1139 - val_loss: 20.3496 - val_accuracy: 0.1518\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.03507194244604317\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f61097f4dd0>\n",
      "Learning rate: 0.08463262855943487\n",
      "Batch size: 5\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - ETA: 0s - loss: 21.1516 - accuracy: 0.1047WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - 65s 322ms/step - loss: 21.1516 - accuracy: 0.1047 - val_loss: 6.6747 - val_accuracy: 0.1990\n",
      "Epoch 2/6\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 12.4724 - accuracy: 0.1283 - val_loss: 8.1144 - val_accuracy: 0.2513\n",
      "Epoch 3/6\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 11.9444 - accuracy: 0.0969 - val_loss: 10.7669 - val_accuracy: 0.1990\n",
      "Epoch 4/6\n",
      "153/153 [==============================] - 46s 302ms/step - loss: 12.1558 - accuracy: 0.1178 - val_loss: 6.4323 - val_accuracy: 0.1466\n",
      "Epoch 5/6\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 13.0419 - accuracy: 0.1217 - val_loss: 11.3829 - val_accuracy: 0.0576\n",
      "Epoch 6/6\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 15.2635 - accuracy: 0.1152 - val_loss: 8.4538 - val_accuracy: 0.1466\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.039612676056338024\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6108d1a8d0>\n",
      "Learning rate: 0.022965425600845264\n",
      "Batch size: 5\n",
      "Epoch 1/9\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - ETA: 0s - loss: 2.6198 - accuracy: 0.1021WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - 64s 314ms/step - loss: 2.6198 - accuracy: 0.1021 - val_loss: 2.1973 - val_accuracy: 0.1466\n",
      "Epoch 2/9\n",
      "153/153 [==============================] - 45s 295ms/step - loss: 2.3765 - accuracy: 0.0812 - val_loss: 2.5043 - val_accuracy: 0.0105\n",
      "Epoch 3/9\n",
      "153/153 [==============================] - 45s 295ms/step - loss: 2.3226 - accuracy: 0.0785 - val_loss: 2.0151 - val_accuracy: 0.1990\n",
      "Epoch 4/9\n",
      "153/153 [==============================] - 45s 295ms/step - loss: 2.3177 - accuracy: 0.0707 - val_loss: 2.1135 - val_accuracy: 0.1047\n",
      "Epoch 5/9\n",
      "153/153 [==============================] - 45s 295ms/step - loss: 2.2854 - accuracy: 0.0720 - val_loss: 2.2042 - val_accuracy: 0.0262\n",
      "Epoch 6/9\n",
      "153/153 [==============================] - 45s 295ms/step - loss: 2.2887 - accuracy: 0.1230 - val_loss: 2.3770 - val_accuracy: 0.0262\n",
      "Epoch 7/9\n",
      "153/153 [==============================] - 45s 294ms/step - loss: 2.1865 - accuracy: 0.0942 - val_loss: 2.0131 - val_accuracy: 0.1518\n",
      "Epoch 8/9\n",
      "153/153 [==============================] - 45s 294ms/step - loss: 2.2584 - accuracy: 0.0759 - val_loss: 2.0990 - val_accuracy: 0.0785\n",
      "Epoch 9/9\n",
      "153/153 [==============================] - 45s 294ms/step - loss: 2.2434 - accuracy: 0.0615 - val_loss: 2.1701 - val_accuracy: 0.0105\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.003099173553719008\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6109849b90>\n",
      "Learning rate: 0.043075549732799014\n",
      "Batch size: 6\n",
      "Epoch 1/8\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - ETA: 0s - loss: 2.9141 - accuracy: 0.1152WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - 63s 374ms/step - loss: 2.9141 - accuracy: 0.1152 - val_loss: 2.0754 - val_accuracy: 0.2513\n",
      "Epoch 2/8\n",
      "128/128 [==============================] - 45s 348ms/step - loss: 2.3120 - accuracy: 0.0641 - val_loss: 2.0537 - val_accuracy: 0.1518\n",
      "Epoch 3/8\n",
      "128/128 [==============================] - 45s 348ms/step - loss: 2.3466 - accuracy: 0.1217 - val_loss: 2.0052 - val_accuracy: 0.2513\n",
      "Epoch 4/8\n",
      "128/128 [==============================] - 45s 348ms/step - loss: 2.2532 - accuracy: 0.0746 - val_loss: 2.1948 - val_accuracy: 0.1518\n",
      "Epoch 5/8\n",
      "128/128 [==============================] - 44s 348ms/step - loss: 2.1508 - accuracy: 0.0733 - val_loss: 2.2203 - val_accuracy: 0.0262\n",
      "Epoch 6/8\n",
      "128/128 [==============================] - 44s 348ms/step - loss: 2.2009 - accuracy: 0.0537 - val_loss: 2.2000 - val_accuracy: 0.0262\n",
      "Epoch 7/8\n",
      "128/128 [==============================] - 44s 348ms/step - loss: 2.1756 - accuracy: 0.0340 - val_loss: 2.1562 - val_accuracy: 0.0785\n",
      "Epoch 8/8\n",
      "128/128 [==============================] - 44s 348ms/step - loss: 2.1711 - accuracy: 0.0484 - val_loss: 2.1904 - val_accuracy: 0.0105\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.003099173553719008\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f6109a86190>\n",
      "Learning rate: 0.08027772281869715\n",
      "Batch size: 4\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 40.8996 - accuracy: 0.1165WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 66s 262ms/step - loss: 40.8996 - accuracy: 0.1165 - val_loss: 44.9245 - val_accuracy: 0.1466\n",
      "Epoch 2/6\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 56.1162 - accuracy: 0.1008 - val_loss: 135.6604 - val_accuracy: 0.0105\n",
      "Epoch 3/6\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 60.4729 - accuracy: 0.1113 - val_loss: 123.4499 - val_accuracy: 0.0262\n",
      "Epoch 4/6\n",
      "191/191 [==============================] - 47s 247ms/step - loss: 54.6579 - accuracy: 0.1008 - val_loss: 82.6264 - val_accuracy: 0.0105\n",
      "Epoch 5/6\n",
      "191/191 [==============================] - 47s 246ms/step - loss: 68.4529 - accuracy: 0.1270 - val_loss: 48.0357 - val_accuracy: 0.0785\n",
      "Epoch 6/6\n",
      "191/191 [==============================] - 47s 247ms/step - loss: 57.3164 - accuracy: 0.1217 - val_loss: 19.9179 - val_accuracy: 0.1990\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.03660714285714286\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f5f4512dc10>\n",
      "Learning rate: 0.08291639926764051\n",
      "Batch size: 6\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - ETA: 0s - loss: 18.2619 - accuracy: 0.1060WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - 65s 376ms/step - loss: 18.2619 - accuracy: 0.1060 - val_loss: 11.0689 - val_accuracy: 0.0262\n",
      "Epoch 2/3\n",
      "128/128 [==============================] - 45s 353ms/step - loss: 10.8632 - accuracy: 0.1126 - val_loss: 12.3346 - val_accuracy: 0.0576\n",
      "Epoch 3/3\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 11.1110 - accuracy: 0.1204 - val_loss: 10.3081 - val_accuracy: 0.0105\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.003099173553719008\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6108db4150>\n",
      "Learning rate: 0.06705609872649387\n",
      "Batch size: 5\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - ETA: 0s - loss: 60.3326 - accuracy: 0.1283WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - 66s 324ms/step - loss: 60.3326 - accuracy: 0.1283 - val_loss: 51.6977 - val_accuracy: 0.1990\n",
      "Epoch 2/7\n",
      "153/153 [==============================] - 46s 304ms/step - loss: 60.9574 - accuracy: 0.1165 - val_loss: 50.4434 - val_accuracy: 0.1466\n",
      "Epoch 3/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 75.4044 - accuracy: 0.1178 - val_loss: 23.0247 - val_accuracy: 0.1466\n",
      "Epoch 4/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 51.2385 - accuracy: 0.0916 - val_loss: 54.5830 - val_accuracy: 0.2513\n",
      "Epoch 5/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 62.3527 - accuracy: 0.1309 - val_loss: 56.7051 - val_accuracy: 0.1466\n",
      "Epoch 6/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 66.7506 - accuracy: 0.1296 - val_loss: 72.1695 - val_accuracy: 0.2513\n",
      "Epoch 7/7\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 58.6768 - accuracy: 0.1257 - val_loss: 95.1260 - val_accuracy: 0.0785\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.016601562500000003\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.gradient_descent.SGD object at 0x7f5f447e0590>\n",
      "Learning rate: 0.01976311428949828\n",
      "Batch size: 5\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - ETA: 0s - loss: 2.4354 - accuracy: 0.1113WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - 64s 316ms/step - loss: 2.4354 - accuracy: 0.1113 - val_loss: 2.1879 - val_accuracy: 0.1990\n",
      "Epoch 2/2\n",
      "153/153 [==============================] - 45s 295ms/step - loss: 2.2574 - accuracy: 0.0955 - val_loss: 2.2627 - val_accuracy: 0.0262\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.0\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f5f454483d0>\n",
      "Learning rate: 0.0412597587618876\n",
      "Batch size: 4\n",
      "Epoch 1/7\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 8.3879 - accuracy: 0.1099WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 68s 270ms/step - loss: 8.3879 - accuracy: 0.1099 - val_loss: 7.7201 - val_accuracy: 0.0785\n",
      "Epoch 2/7\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 6.5395 - accuracy: 0.1309 - val_loss: 4.3647 - val_accuracy: 0.0785\n",
      "Epoch 3/7\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 5.7382 - accuracy: 0.1165 - val_loss: 6.2593 - val_accuracy: 0.0785\n",
      "Epoch 4/7\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 6.6979 - accuracy: 0.1060 - val_loss: 3.8425 - val_accuracy: 0.0576\n",
      "Epoch 5/7\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 6.2874 - accuracy: 0.1126 - val_loss: 5.0308 - val_accuracy: 0.1518\n",
      "Epoch 6/7\n",
      "191/191 [==============================] - 48s 252ms/step - loss: 7.1267 - accuracy: 0.0929 - val_loss: 2.3671 - val_accuracy: 0.1990\n",
      "Epoch 7/7\n",
      "191/191 [==============================] - 48s 254ms/step - loss: 6.2028 - accuracy: 0.1113 - val_loss: 6.4875 - val_accuracy: 0.0785\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.016601562500000003\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5f444ba5d0>\n",
      "Learning rate: 0.09847960333122538\n",
      "Batch size: 4\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 79.9710 - accuracy: 0.1348WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 69s 272ms/step - loss: 79.9710 - accuracy: 0.1348 - val_loss: 212.1694 - val_accuracy: 0.0262\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.0\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f6155b5ab90>\n",
      "Learning rate: 0.09626070959915467\n",
      "Batch size: 4\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 23.5891 - accuracy: 0.1243WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 69s 270ms/step - loss: 23.5891 - accuracy: 0.1243 - val_loss: 22.6111 - val_accuracy: 0.0105\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 16.8069 - accuracy: 0.0969 - val_loss: 14.5739 - val_accuracy: 0.0105\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 12.7074 - accuracy: 0.1243 - val_loss: 10.6149 - val_accuracy: 0.1518\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 18.7384 - accuracy: 0.1021 - val_loss: 15.1285 - val_accuracy: 0.0785\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 15.3782 - accuracy: 0.1348 - val_loss: 17.4345 - val_accuracy: 0.1990\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 48s 252ms/step - loss: 16.4834 - accuracy: 0.1270 - val_loss: 9.1810 - val_accuracy: 0.1990\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 14.7484 - accuracy: 0.1034 - val_loss: 10.5679 - val_accuracy: 0.2513\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 14.5558 - accuracy: 0.1230 - val_loss: 6.5582 - val_accuracy: 0.0785\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 13.7303 - accuracy: 0.1152 - val_loss: 10.4941 - val_accuracy: 0.0576\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 15.9811 - accuracy: 0.1414 - val_loss: 4.9581 - val_accuracy: 0.2513\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.0560064935064935\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5f448dbc10>\n",
      "Learning rate: 0.097733305456775\n",
      "Batch size: 4\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 89.8974 - accuracy: 0.1152WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 69s 271ms/step - loss: 89.8974 - accuracy: 0.1152 - val_loss: 71.7484 - val_accuracy: 0.0262\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 82.2911 - accuracy: 0.1466 - val_loss: 69.1404 - val_accuracy: 0.0262\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 48s 254ms/step - loss: 89.4900 - accuracy: 0.1230 - val_loss: 59.4100 - val_accuracy: 0.2513\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 109.3917 - accuracy: 0.1139 - val_loss: 102.9059 - val_accuracy: 0.1466\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 99.2645 - accuracy: 0.0955 - val_loss: 53.2472 - val_accuracy: 0.0576\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 97.7829 - accuracy: 0.1008 - val_loss: 103.8145 - val_accuracy: 0.0785\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 106.3193 - accuracy: 0.1165 - val_loss: 43.3201 - val_accuracy: 0.0576\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 106.8021 - accuracy: 0.1034 - val_loss: 69.7138 - val_accuracy: 0.0785\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 92.3279 - accuracy: 0.1217 - val_loss: 34.6194 - val_accuracy: 0.2513\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 97.8863 - accuracy: 0.1165 - val_loss: 142.4531 - val_accuracy: 0.0576\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.012896825396825396\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f5f44ff0810>\n",
      "Learning rate: 0.09831972062376428\n",
      "Batch size: 6\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - ETA: 0s - loss: 18.3955 - accuracy: 0.1191WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - 65s 377ms/step - loss: 18.3955 - accuracy: 0.1191 - val_loss: 11.9559 - val_accuracy: 0.2513\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 15.2491 - accuracy: 0.1230 - val_loss: 9.2027 - val_accuracy: 0.1990\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 17.1305 - accuracy: 0.1086 - val_loss: 10.9764 - val_accuracy: 0.1518\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 11.6099 - accuracy: 0.0982 - val_loss: 6.8774 - val_accuracy: 0.0785\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 13.2539 - accuracy: 0.0995 - val_loss: 12.5318 - val_accuracy: 0.0785\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 12.1308 - accuracy: 0.1165 - val_loss: 13.8125 - val_accuracy: 0.0262\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 12.9041 - accuracy: 0.1178 - val_loss: 19.2588 - val_accuracy: 0.0105\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 15.4465 - accuracy: 0.1152 - val_loss: 9.6649 - val_accuracy: 0.0785\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 45s 353ms/step - loss: 12.3726 - accuracy: 0.0982 - val_loss: 8.8024 - val_accuracy: 0.1990\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 15.4527 - accuracy: 0.1060 - val_loss: 6.7733 - val_accuracy: 0.1990\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.03660714285714286\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f6106182990>\n",
      "Learning rate: 0.007055410990180815\n",
      "Batch size: 4\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 3.1524 - accuracy: 0.0759WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 68s 268ms/step - loss: 3.1524 - accuracy: 0.0759 - val_loss: 2.2695 - val_accuracy: 0.1518\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.9330 - accuracy: 0.0929 - val_loss: 3.0631 - val_accuracy: 0.0105\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.8365 - accuracy: 0.0838 - val_loss: 3.0797 - val_accuracy: 0.1518\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.9421 - accuracy: 0.0890 - val_loss: 3.0347 - val_accuracy: 0.1466\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.6917 - accuracy: 0.0903 - val_loss: 2.8678 - val_accuracy: 0.0262\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.8705 - accuracy: 0.0942 - val_loss: 4.4948 - val_accuracy: 0.0262\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 48s 254ms/step - loss: 2.9294 - accuracy: 0.0995 - val_loss: 2.2786 - val_accuracy: 0.0262\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.7858 - accuracy: 0.0903 - val_loss: 2.2296 - val_accuracy: 0.0785\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.8396 - accuracy: 0.0825 - val_loss: 2.5660 - val_accuracy: 0.0262\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 48s 253ms/step - loss: 2.7395 - accuracy: 0.0812 - val_loss: 2.8064 - val_accuracy: 0.0576\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.012896825396825396\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f61099a20d0>\n",
      "Learning rate: 0.09956873101717105\n",
      "Batch size: 6\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - ETA: 0s - loss: 92.1737 - accuracy: 0.1152WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - 66s 379ms/step - loss: 92.1737 - accuracy: 0.1152 - val_loss: 53.2033 - val_accuracy: 0.1518\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 46s 356ms/step - loss: 86.6937 - accuracy: 0.1060 - val_loss: 70.0738 - val_accuracy: 0.1518\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 46s 356ms/step - loss: 63.9867 - accuracy: 0.1257 - val_loss: 31.2426 - val_accuracy: 0.0262\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 46s 356ms/step - loss: 65.1540 - accuracy: 0.1204 - val_loss: 98.9913 - val_accuracy: 0.0785\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 46s 356ms/step - loss: 78.2307 - accuracy: 0.1257 - val_loss: 88.1695 - val_accuracy: 0.0262\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 75.0634 - accuracy: 0.1008 - val_loss: 79.0453 - val_accuracy: 0.1466\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 70.2054 - accuracy: 0.1086 - val_loss: 54.9826 - val_accuracy: 0.0576\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 91.2986 - accuracy: 0.1034 - val_loss: 40.1555 - val_accuracy: 0.1466\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 89.6088 - accuracy: 0.1374 - val_loss: 53.5002 - val_accuracy: 0.2513\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 46s 356ms/step - loss: 69.8205 - accuracy: 0.1296 - val_loss: 37.4457 - val_accuracy: 0.1466\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.039612676056338024\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f6106bf1b10>\n",
      "Learning rate: 0.0993969704156768\n",
      "Batch size: 5\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - ETA: 0s - loss: 68.4524 - accuracy: 0.0969WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - 66s 325ms/step - loss: 68.4524 - accuracy: 0.0969 - val_loss: 50.8198 - val_accuracy: 0.1466\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 46s 304ms/step - loss: 78.4397 - accuracy: 0.1034 - val_loss: 70.8707 - val_accuracy: 0.1466\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 46s 304ms/step - loss: 80.9261 - accuracy: 0.1217 - val_loss: 117.8199 - val_accuracy: 0.0262\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 46s 304ms/step - loss: 82.3119 - accuracy: 0.1152 - val_loss: 65.7262 - val_accuracy: 0.0785\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 47s 304ms/step - loss: 71.5770 - accuracy: 0.1099 - val_loss: 30.0050 - val_accuracy: 0.0785\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 93.6768 - accuracy: 0.1073 - val_loss: 26.3244 - val_accuracy: 0.2513\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 91.5848 - accuracy: 0.1034 - val_loss: 135.5225 - val_accuracy: 0.0105\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 90.4798 - accuracy: 0.1348 - val_loss: 118.4723 - val_accuracy: 0.1466\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 107.8189 - accuracy: 0.1178 - val_loss: 92.2085 - val_accuracy: 0.0576\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 46s 303ms/step - loss: 82.9155 - accuracy: 0.1073 - val_loss: 98.5268 - val_accuracy: 0.0105\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.003099173553719008\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f5f4472d690>\n",
      "Learning rate: 0.0014390961417010857\n",
      "Batch size: 4\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.4214 - accuracy: 0.0890WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 69s 270ms/step - loss: 2.4214 - accuracy: 0.0890 - val_loss: 2.6676 - val_accuracy: 0.0105\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.003099173553719008\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f5f4473b210>\n",
      "Learning rate: 0.0008412887381573209\n",
      "Batch size: 6\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - ETA: 0s - loss: 2.3333 - accuracy: 0.0838WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - 65s 378ms/step - loss: 2.3333 - accuracy: 0.0838 - val_loss: 2.1894 - val_accuracy: 0.0785\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.2163 - accuracy: 0.0825 - val_loss: 2.3640 - val_accuracy: 0.0105\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.2014 - accuracy: 0.0746 - val_loss: 2.2476 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.1884 - accuracy: 0.0668 - val_loss: 2.1515 - val_accuracy: 0.1990\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.1945 - accuracy: 0.1296 - val_loss: 2.1673 - val_accuracy: 0.1466\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 2.1906 - accuracy: 0.0602 - val_loss: 2.1343 - val_accuracy: 0.1990\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.1959 - accuracy: 0.1047 - val_loss: 2.2024 - val_accuracy: 0.0262\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.2135 - accuracy: 0.0890 - val_loss: 2.1232 - val_accuracy: 0.1518\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.1783 - accuracy: 0.0969 - val_loss: 2.1138 - val_accuracy: 0.2513\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.1709 - accuracy: 0.1191 - val_loss: 2.1782 - val_accuracy: 0.1990\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.03660714285714286\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f61554c1b10>\n",
      "Learning rate: 0.005925964699642209\n",
      "Batch size: 6\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - ETA: 0s - loss: 2.7882 - accuracy: 0.1099WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - 66s 378ms/step - loss: 2.7882 - accuracy: 0.1099 - val_loss: 2.1116 - val_accuracy: 0.2513\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 45s 355ms/step - loss: 2.6192 - accuracy: 0.0995 - val_loss: 2.4803 - val_accuracy: 0.0785\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.6169 - accuracy: 0.0825 - val_loss: 2.2737 - val_accuracy: 0.0576\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.6316 - accuracy: 0.1008 - val_loss: 2.9008 - val_accuracy: 0.0262\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.6157 - accuracy: 0.0916 - val_loss: 2.1812 - val_accuracy: 0.1990\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.4722 - accuracy: 0.0785 - val_loss: 2.6277 - val_accuracy: 0.0576\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.5203 - accuracy: 0.1178 - val_loss: 3.4820 - val_accuracy: 0.0262\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.7840 - accuracy: 0.0785 - val_loss: 2.0926 - val_accuracy: 0.1990\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.5315 - accuracy: 0.0785 - val_loss: 2.4597 - val_accuracy: 0.0105\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 45s 354ms/step - loss: 2.7567 - accuracy: 0.0641 - val_loss: 2.9490 - val_accuracy: 0.0262\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.0\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f61070df110>\n",
      "Learning rate: 0.09986478730968087\n",
      "Batch size: 6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - ETA: 0s - loss: 22.1666 - accuracy: 0.1139WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "128/128 [==============================] - 65s 377ms/step - loss: 22.1666 - accuracy: 0.1139 - val_loss: 16.4599 - val_accuracy: 0.0576\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.012896825396825396\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f610890a0d0>\n",
      "Learning rate: 0.09839421140639927\n",
      "Batch size: 4\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 83.7861 - accuracy: 0.1021WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 68s 270ms/step - loss: 83.7861 - accuracy: 0.1021 - val_loss: 83.7431 - val_accuracy: 0.1990\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 100.0473 - accuracy: 0.1414 - val_loss: 216.8045 - val_accuracy: 0.0105\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 89.5484 - accuracy: 0.0720 - val_loss: 90.1326 - val_accuracy: 0.1518\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 103.6669 - accuracy: 0.1335 - val_loss: 131.6423 - val_accuracy: 0.1990\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 86.4270 - accuracy: 0.1139 - val_loss: 25.7243 - val_accuracy: 0.1466\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 80.7606 - accuracy: 0.1152 - val_loss: 120.6496 - val_accuracy: 0.1466\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 108.4474 - accuracy: 0.1021 - val_loss: 137.2168 - val_accuracy: 0.0105\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 88.0409 - accuracy: 0.1152 - val_loss: 149.5176 - val_accuracy: 0.0576\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 94.8436 - accuracy: 0.1073 - val_loss: 37.0569 - val_accuracy: 0.1990\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 87.9783 - accuracy: 0.1021 - val_loss: 49.3131 - val_accuracy: 0.1990\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.03660714285714286\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adamax.Adamax object at 0x7f610710f190>\n",
      "Learning rate: 0.09999607299165171\n",
      "Batch size: 5\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - ETA: 0s - loss: 23.7695 - accuracy: 0.1126WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "153/153 [==============================] - 66s 322ms/step - loss: 23.7695 - accuracy: 0.1126 - val_loss: 18.1088 - val_accuracy: 0.0785\n",
      "Epoch 2/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 15.7515 - accuracy: 0.1099 - val_loss: 6.9642 - val_accuracy: 0.1518\n",
      "Epoch 3/10\n",
      "153/153 [==============================] - 46s 302ms/step - loss: 15.0045 - accuracy: 0.0955 - val_loss: 9.7979 - val_accuracy: 0.1990\n",
      "Epoch 4/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 18.6392 - accuracy: 0.1387 - val_loss: 7.5946 - val_accuracy: 0.2513\n",
      "Epoch 5/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 11.1085 - accuracy: 0.1191 - val_loss: 5.3586 - val_accuracy: 0.0576\n",
      "Epoch 6/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 12.1689 - accuracy: 0.0916 - val_loss: 12.7876 - val_accuracy: 0.0785\n",
      "Epoch 7/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 17.7301 - accuracy: 0.0929 - val_loss: 9.5714 - val_accuracy: 0.0576\n",
      "Epoch 8/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 14.8582 - accuracy: 0.1113 - val_loss: 22.6501 - val_accuracy: 0.0105\n",
      "Epoch 9/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 12.9621 - accuracy: 0.1191 - val_loss: 15.9398 - val_accuracy: 0.0785\n",
      "Epoch 10/10\n",
      "153/153 [==============================] - 46s 301ms/step - loss: 12.8600 - accuracy: 0.1152 - val_loss: 11.5718 - val_accuracy: 0.1518\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.03507194244604317\n",
      "clear sessions\n",
      "begin downloaden tokenizer\n",
      "begin downloaden model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaden klaar\n",
      "--------------------STARTING TRAINING--------------------\n",
      "Optimization function: <tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f5f44ab0190>\n",
      "Learning rate: 0.00010125993823601541\n",
      "Batch size: 4\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - ETA: 0s - loss: 2.1352 - accuracy: 0.2448WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "191/191 [==============================] - 69s 270ms/step - loss: 2.1352 - accuracy: 0.2448 - val_loss: 2.0088 - val_accuracy: 0.2461\n",
      "Epoch 2/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 2.3122 - accuracy: 0.0537 - val_loss: 2.1572 - val_accuracy: 0.1518\n",
      "Epoch 3/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 2.2498 - accuracy: 0.0589 - val_loss: 2.2434 - val_accuracy: 0.0105\n",
      "Epoch 4/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 2.2164 - accuracy: 0.0903 - val_loss: 2.0572 - val_accuracy: 0.1518\n",
      "Epoch 5/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 2.2284 - accuracy: 0.1387 - val_loss: 2.2018 - val_accuracy: 0.0785\n",
      "Epoch 6/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 2.2387 - accuracy: 0.0838 - val_loss: 2.1531 - val_accuracy: 0.2513\n",
      "Epoch 7/10\n",
      "191/191 [==============================] - 49s 255ms/step - loss: 2.1938 - accuracy: 0.0668 - val_loss: 2.0845 - val_accuracy: 0.1990\n",
      "Epoch 8/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 2.2115 - accuracy: 0.0798 - val_loss: 2.1460 - val_accuracy: 0.1466\n",
      "Epoch 9/10\n",
      "191/191 [==============================] - 49s 254ms/step - loss: 2.2066 - accuracy: 0.0720 - val_loss: 2.2437 - val_accuracy: 0.0785\n",
      "Epoch 10/10\n",
      "191/191 [==============================] - 48s 254ms/step - loss: 2.2013 - accuracy: 0.0785 - val_loss: 2.2210 - val_accuracy: 0.0105\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "macro f1_score: 0.003099173553719008\n"
     ]
    }
   ],
   "source": [
    "# Run Bayesian optimization.\n",
    "gp_results = gp_minimize(func=to_optimize, dimensions=dimensions, acq_func='EI', random_state=1, x0=default, n_calls=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1625062355039,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "pSdmVlU4Lfdb"
   },
   "outputs": [],
   "source": [
    "with open(BASE_PATH+'gp_results_final.pkl', 'wb') as f:\n",
    "  pickle.dump(gp_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1625062355039,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "i7LD_EWmL6Jh"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns = ['optimizer', 'learning_rate', 'batch_size', 'num_epochs'])\n",
    "for i in gp_results['x_iters']:\n",
    "  series = pd.Series(i, index = results_df.columns)\n",
    "  results_df = results_df.append(series, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625062355039,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "ChV5hit8ExZe"
   },
   "outputs": [],
   "source": [
    "results_df['-f1'] = pd.Series(gp_results['func_vals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1625062355040,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "cokYuLAtFKSR"
   },
   "outputs": [],
   "source": [
    "results_df['f1'] = results_df['-f1'].apply(lambda x: -x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1625062355545,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "04Y2dxlMFdHu"
   },
   "outputs": [],
   "source": [
    "results_df.sort_values('f1', ascending=False).to_excel(BASE_PATH+'bayesian_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1625062355546,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "CfI7PN6VTTWT"
   },
   "outputs": [],
   "source": [
    "with open(BASE_PATH+'gp_results_final.pkl', 'rb') as f:\n",
    "  gp_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1625065515806,
     "user": {
      "displayName": "Jasper Nieuwdorp",
      "photoUrl": "",
      "userId": "03567778344719696800"
     },
     "user_tz": -120
    },
    "id": "hgXkAVx-Tc5O",
    "outputId": "33f7bfae-3324-4815-b84f-d26ed11a0bdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensorflow.python.keras.optimizer_v2.adamax.Adamax,\n",
       " 0.09626070959915467,\n",
       " 4,\n",
       " 10]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp_results['x']"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMhf/PahWjYNQ3zy0P4FRl0",
   "collapsed_sections": [
    "JdgC1O7yk-w3"
   ],
   "machine_shape": "hm",
   "mount_file_id": "1gXr5ZtaG5fNrSywZWifYT8PliHOtqB-H",
   "name": "Bayesian-HPSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
